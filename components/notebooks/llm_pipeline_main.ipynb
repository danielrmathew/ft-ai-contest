{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28193354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ba0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core import set_global_tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d6cb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drmathew/.local/lib/python3.9/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228811ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a402fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = \"rxfMXxfsdsKGb8urL8shecBbBp37ZBuvU5zo39sm\" # should change this to secret token\n",
    "API_ENDPOINT = f\"https://api.marketaux.com/v1/news/all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf237f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"api_token\": API_TOKEN,\n",
    "    \"entity_types\": \"equity,index,etf\", # should include industries parameter\n",
    "#     \"industries\": \"Technology\",\n",
    "    \"countries\": \"us\",\n",
    "    \"published_after\": \"2024-05-01T13:00\",\n",
    "    \"published_before\": \"2024-05-01T14:00\",\n",
    "    \"domains\": \"finance.yahoo.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(payload):\n",
    "    \"\"\"\n",
    "    Retrieves URLs of articles from Yahoo Finance\n",
    "    payload: dict, criteria for article selection\n",
    "    return: list, Yahoo Finance article URLs\n",
    "    \"\"\"\n",
    "    r = requests.get(\"https://api.marketaux.com/v1/news/all\", params=payload)\n",
    "    output = r.text\n",
    "    json_output = json.loads(output)\n",
    "    data = json_output['data']\n",
    "    \n",
    "    urls = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        url = data[i]['url']\n",
    "        if url.startswith(\"https://finance.yahoo.com/news\"):\n",
    "            urls.append(url)\n",
    "        \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14925e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_content(url):\n",
    "    \"\"\"\n",
    "    Retrieves article content\n",
    "    url: str, article URL\n",
    "    return: str, article content\n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    if r.status_code != 200:\n",
    "        return 'Invalid Response'\n",
    "    \n",
    "    soup = BeautifulSoup(r.content)\n",
    "    body = soup.find('div', attrs={'class': 'caas-body'})\n",
    "    content = \"\"\n",
    "    \n",
    "    for text in body.find_all('p'):\n",
    "        content += text.text\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6bdbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(filename, content):\n",
    "    \"\"\"\n",
    "    Creates and writes article content to file\n",
    "    filename: str, name of file to create\n",
    "    content: str, content to write to file\n",
    "    \"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c76752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(start_date, num_days):\n",
    "    \"\"\"\n",
    "    Retrieves article content over a number of days and saves the content to files in the 'articles' folder\n",
    "    start_date: str, date in the format YYYY-MM-DD. articles published on this day are retrieved\n",
    "    num_days: int, the number of days after start_date to retrieve articles for. i.e. if num_days=10, articles published \n",
    "        on the start_date and every day between the start_date and 10 days after are retrieved\n",
    "    \"\"\"\n",
    "    # start_date looks like \"2024-05-01\"\n",
    "    payload = {\n",
    "        \"api_token\": API_TOKEN,\n",
    "        \"entity_types\": \"equity,index,etf\", \n",
    "        \"countries\": \"us\",\n",
    "#         \"published_after\": \"2024-05-10T13:00\", # what time format is supposed to look like, in UTC format \n",
    "#         \"published_before\": \"2024-05-10T14:00\",\n",
    "        \"domains\": \"finance.yahoo.com\"\n",
    "    }\n",
    "    \n",
    "    def get_dates(start_date, num_days):\n",
    "        # Convert the input string to a datetime object\n",
    "        date_obj = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        dates = [date_obj.strftime('%Y-%m-%d')]\n",
    "        # Print the input date\n",
    "        print(date_obj.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "        # Loop to get a total of num_days days\n",
    "        for i in range(1, num_days):\n",
    "            next_day = date_obj + timedelta(days=i)\n",
    "            dates.append(next_day.strftime('%Y-%m-%d'))\n",
    "            print(f\"{next_day.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        return dates\n",
    "        \n",
    "    dates = get_dates(start_date, num_days)\n",
    "    \n",
    "    for date in dates: \n",
    "        for add_hour in range(7): \n",
    "            start = date + \"T\" + str(13 + add_hour) + \":00\" # edit str(xx) for start day\n",
    "            finish = date + \"T\" + str(13 + add_hour + 1) + \":00\"\n",
    "            payload[\"published_after\"] = start\n",
    "            payload[\"published_before\"] = finish\n",
    "            \n",
    "            urls = get_urls(payload)\n",
    "            for i in range(len(urls)):\n",
    "                print(urls[i])\n",
    "                content = get_article_content(urls[i])\n",
    "                if content != \"Invalid Response\": \n",
    "                    filename = os.path.join(\"..\", \"..\", \"articles\", \"article_\" + start + \"_\" + str(add_hour) + str(i) + \".txt\")\n",
    "                    write_to_file(filename, content)\n",
    "                else:\n",
    "                    print(\"Above URL Skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64e51541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm(selected_model):\n",
    "    \"\"\"\n",
    "    Initializes and stores LLM on memory\n",
    "    selected_model: str, model name to load\n",
    "    return: model variable\n",
    "    \"\"\"\n",
    "    \n",
    "    SYSTEM_PROMPT = \"\"\"You are an AI assistant that answers questions in a friendly manner, based on the given source documents. Here are some rules you always follow:\n",
    "    - Generate human readable output, avoid creating output with gibberish text.\n",
    "    - Generate only the requested output, don't include any other language before or after the requested output.\n",
    "    - Never say thank you, that you are happy to help, that you are an AI agent, etc. Just answer directly.\n",
    "    - Generate professional language typically used in business documents in North America.\n",
    "    - Never generate offensive or foul language.\n",
    "    \"\"\"\n",
    "\n",
    "    query_wrapper_prompt = PromptTemplate(\n",
    "        \"[INST]<<SYS>>\\n\" + SYSTEM_PROMPT + \"<</SYS>>\\n\\n{query_str}[/INST] \"\n",
    "    )\n",
    "\n",
    "    llm = HuggingFaceLLM(\n",
    "        context_window=4096,\n",
    "        max_new_tokens=2048,\n",
    "        generate_kwargs={\"temperature\": 0.1, \"do_sample\": True},\n",
    "        query_wrapper_prompt=query_wrapper_prompt,\n",
    "        tokenizer_name=selected_model,\n",
    "        model_name=selected_model,\n",
    "        device_map=\"auto\",\n",
    "        # change these settings below depending on your GPU\n",
    "        model_kwargs={\"torch_dtype\": torch.float16, \"load_in_8bit\": True},\n",
    "    )\n",
    "        \n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e04263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_engine(llm):\n",
    "    \"\"\"\n",
    "    Creates the necessary components to run a RAG pipeline\n",
    "    llm: LLM object loaded into memory\n",
    "    return: SimpleDirectoryReader, VectorStoreIndex, QueryEngine. the first object houses the data, the second object indexes\n",
    "        the data for fast retrieval, and the third object is how we can query the data using the LLM\n",
    "    \"\"\"\n",
    "    set_global_tokenizer(\n",
    "        AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\").encode\n",
    "    )\n",
    "    embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "    \n",
    "    yf_documents = SimpleDirectoryReader(input_dir=\"../../articles\").load_data()\n",
    "    yf_index = VectorStoreIndex.from_documents(yf_documents, embed_model=embed_model)\n",
    "    yf_query_engine = yf_index.as_query_engine(llm=llm)\n",
    "    \n",
    "    return yf_documents, yf_index, yf_query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41425cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stocks(query_engine, user_prefs):\n",
    "    \"\"\"\n",
    "    Returns set of stocks to invest in based on customer preferences and market news\n",
    "    llm: LLM object loaded into memory\n",
    "    user_prefs: dict, has keys \"num_stocks\", \"risk\", \"industries\", \"return_goals\", contains information about user preferences\n",
    "    return: list, set of stocks matching user preferences returned from LLM based on articles \n",
    "    \"\"\"\n",
    "    \n",
    "    start_prompt = (\"Gather the financial securities that are mentioned across the articles the most in a positive sentiment.\"\n",
    "     f\" The securities gathered can be stocks or ETFs. Return a list of {user_prefs['num_stocks']} securities in which no more than\"\n",
    "     \" half of the securities are from the same industry. \")\n",
    "    risk_averse = (\"This list of securities should be tailored to a very risk averse investor who \"\n",
    "        \"is more focused on stability instead of rapid growth. \")\n",
    "    risk_neutral = \"\"\n",
    "    risk_tolerant = (\"This list of securities should also be tailored to a very risk tolerant investor who \"\n",
    "        \"is more focused on rapid growth instead of stability. This list should include growth stocks with high expected returns \" \n",
    "        \"and the potential for greater risk. \")\n",
    "    industries_prompt = f\"Include multiple stocks with a strong focus on the following industry or industries: {user_prefs['industries']}. \"\n",
    "    end_prompt = (\"Create this list so that they can be put together to make a diversified portfolio. \" \n",
    "        \"List the stock name, stock ticker in parentheses, and the industry associated with it \" \n",
    "        \"and double check that a majority of the industries aren't the same.\")\n",
    "    \n",
    "    prompt_dict = {\n",
    "        \"risk_averse\": risk_averse, \n",
    "        \"risk_neutral\": risk_neutral,\n",
    "        \"risk_tolerant\": risk_tolerant\n",
    "    }\n",
    "    prompt = None\n",
    "    \n",
    "    if user_prefs[\"risk\"] == \"conservative\":\n",
    "        prompt = start_prompt + prompt_dict[\"risk_averse\"]\n",
    "    elif user_prefs[\"risk\"] == \"aggressive\":\n",
    "        prompt = start_prompt + prompt_dict[\"risk_tolerant\"]\n",
    "    else:\n",
    "        prompt = start_prompt + prompt_dict[\"risk_neutral\"]\n",
    "        \n",
    "    if user_prefs['industries']:\n",
    "        prompt += industries_prompt\n",
    "        \n",
    "    prompt += end_prompt\n",
    "        \n",
    "    \n",
    "    print(prompt)\n",
    "    \n",
    "    VALID = False\n",
    "    attempts = 0\n",
    "    \n",
    "    while not VALID:\n",
    "        attempts += 1\n",
    "        print(attempts)\n",
    "        response = query_engine.query(prompt)\n",
    "    \n",
    "        pattern = r'\\(([A-Za-z]+)\\)'\n",
    "        stocks = re.findall(pattern, response.response)\n",
    "    \n",
    "    \n",
    "        for ticker in stocks:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            if 'regularMarketOpen' not in stock.info:\n",
    "                VALID = False\n",
    "                break\n",
    "            else:\n",
    "                VALID = True\n",
    "                \n",
    "    return stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_options = [\"conservative\", \"moderate\", \"aggressive\"]\n",
    "industry_options = [\"Energy\", \"Materials\", \"Industrials\", \"Utilities\", \"Healthcare\", \"Financials\", \"Consumer Discretionary\",\n",
    "                    \"Consumer Staples\", \"Technology\", \"Communication Services\", \"Real Estate\"]\n",
    "return_goals = []\n",
    "user_prefs = {\n",
    "    \"num_stocks\": None, \n",
    "    \"risk\": None, \n",
    "    \"industries\": None, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "643d78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA2_7B_CHAT = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "selected_model = LLAMA2_7B_CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aab81ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create_documents(\"2024-05-20\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "775a0e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926c1cf60e444fc3a7aaf2bc2de54936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# llm = get_llm(selected_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30341b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs, index, query_engine = get_query_engine(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example user preferences\n",
    "user_prefs = {\"num_stocks\": 5, \"risk\": \"conservative\", \"industries\": None}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
