{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28193354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ba0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core import set_global_tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d6cb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drmathew/.local/lib/python3.9/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "228811ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "64e51541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm(selected_model):\n",
    "    SYSTEM_PROMPT = \"\"\"You are an AI assistant that answers questions in a friendly manner, based on the given source documents. Here are some rules you always follow:\n",
    "    - Generate human readable output, avoid creating output with gibberish text.\n",
    "    - Generate only the requested output, don't include any other language before or after the requested output.\n",
    "    - Never say thank you, that you are happy to help, that you are an AI agent, etc. Just answer directly.\n",
    "    - Generate professional language typically used in business documents in North America.\n",
    "    - Never generate offensive or foul language.\n",
    "    \"\"\"\n",
    "\n",
    "    query_wrapper_prompt = PromptTemplate(\n",
    "        \"[INST]<<SYS>>\\n\" + SYSTEM_PROMPT + \"<</SYS>>\\n\\n{query_str}[/INST] \"\n",
    "    )\n",
    "\n",
    "    llm = HuggingFaceLLM(\n",
    "        context_window=4096,\n",
    "        max_new_tokens=2048,\n",
    "        generate_kwargs={\"temperature\": 0.1, \"do_sample\": True},\n",
    "        query_wrapper_prompt=query_wrapper_prompt,\n",
    "        tokenizer_name=selected_model,\n",
    "        model_name=selected_model,\n",
    "        device_map=\"auto\",\n",
    "        # change these settings below depending on your GPU\n",
    "        model_kwargs={\"torch_dtype\": torch.float16, \"load_in_8bit\": True},\n",
    "    )\n",
    "        \n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a402fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = \"rxfMXxfsdsKGb8urL8shecBbBp37ZBuvU5zo39sm\" # should change this to secret token\n",
    "API_ENDPOINT = f\"https://api.marketaux.com/v1/news/all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faf237f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"api_token\": API_TOKEN,\n",
    "    \"entity_types\": \"equity,index,etf\", # should include industries parameter\n",
    "#     \"industries\": \"Technology\",\n",
    "    \"countries\": \"us\",\n",
    "    \"published_after\": \"2024-05-01T13:00\",\n",
    "    \"published_before\": \"2024-05-01T14:00\",\n",
    "    \"domains\": \"finance.yahoo.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbda32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(payload):\n",
    "    r = requests.get(\"https://api.marketaux.com/v1/news/all\", params=payload)\n",
    "    output = r.text\n",
    "    json_output = json.loads(output)\n",
    "    data = json_output['data']\n",
    "    \n",
    "    urls = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        url = data[i]['url']\n",
    "        if url.startswith(\"https://finance.yahoo.com/news\"):\n",
    "            urls.append(url)\n",
    "        \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14925e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_content(url):\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    if r.status_code != 200:\n",
    "        return 'Invalid Response'\n",
    "    \n",
    "    soup = BeautifulSoup(r.content)\n",
    "    body = soup.find('div', attrs={'class': 'caas-body'})\n",
    "    content = \"\"\n",
    "    \n",
    "    for text in body.find_all('p'):\n",
    "        content += text.text\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e6bdbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(filename, content):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c76752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(start_date, num_days):\n",
    "    # start_date looks like \"2024-05-01\"\n",
    "    payload = {\n",
    "        \"api_token\": API_TOKEN,\n",
    "        \"entity_types\": \"equity,index,etf\", \n",
    "        \"countries\": \"us\",\n",
    "#         \"published_after\": \"2024-05-10T13:00\", # what time format is supposed to look like, in UTC format \n",
    "#         \"published_before\": \"2024-05-10T14:00\",\n",
    "        \"domains\": \"finance.yahoo.com\"\n",
    "    }\n",
    "    \n",
    "    def get_dates(start_date, num_days):\n",
    "        # Convert the input string to a datetime object\n",
    "        date_obj = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        dates = [date_obj.strftime('%Y-%m-%d')]\n",
    "        # Print the input date\n",
    "        print(date_obj.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "        # Loop to get a total of num_days days\n",
    "        for i in range(1, num_days):\n",
    "            next_day = date_obj + timedelta(days=i)\n",
    "            dates.append(next_day.strftime('%Y-%m-%d'))\n",
    "            print(f\"{next_day.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        return dates\n",
    "        \n",
    "    dates = get_dates(start_date, num_days)\n",
    "    \n",
    "    for date in dates: \n",
    "        for add_hour in range(7): \n",
    "            start = date + \"T\" + str(13 + add_hour) + \":00\" # edit str(xx) for start day\n",
    "            finish = date + \"T\" + str(13 + add_hour + 1) + \":00\"\n",
    "            payload[\"published_after\"] = start\n",
    "            payload[\"published_before\"] = finish\n",
    "            \n",
    "            urls = get_urls(payload)\n",
    "            for i in range(len(urls)):\n",
    "                print(urls[i])\n",
    "                content = get_article_content(urls[i])\n",
    "                if content != \"Invalid Response\": \n",
    "                    filename = os.path.join(\"..\", \"..\", \"articles\", \"article_\" + start + \"_\" + str(add_hour) + str(i) + \".txt\")\n",
    "                    write_to_file(filename, content)\n",
    "                else:\n",
    "                    print(\"Above URL Skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "10e04263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_engine(llm):\n",
    "    set_global_tokenizer(\n",
    "        AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\").encode\n",
    "    )\n",
    "    embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "    \n",
    "    yf_documents = SimpleDirectoryReader(input_dir=\"articles\").load_data()\n",
    "    yf_index = VectorStoreIndex.from_documents(yf_documents, embed_model=embed_model)\n",
    "    yf_query_engine = yf_index.as_query_engine(llm=llm)\n",
    "    \n",
    "    return yf_documents, yf_index, yf_query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "41425cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stocks(llm, user_prefs):\n",
    "    docs, index, query_engine = get_query_engine(llm)\n",
    "    \n",
    "    risk_averse_prompt = \"Gather the financial securities that are most mentioned across the articles in a positive sentiment.\" + \\\n",
    "    f\"The securities gathered can be stocks or ETFs. Return a list of {user_prefs['num_stocks']} securities in which no more than half of the \" + \\\n",
    "    \"securities are from the same industry. This list of securities should also be tailored to a very risk averse investor who \" + \\\n",
    "    \"is more focused on stability instead of rapid growth. \"\n",
    "    if user_prefs['industries']:\n",
    "        risk_averse_prompt += f\"Include multiple stocks with a strong focus on the following industry or industries: {user_prefs['industries']}. \"\n",
    "    risk_averse_prompt += \"Create this list so that they can be put together to make a diversified portfolio. \" + \\\n",
    "    \"List the stock name, stock ticker in parentheses, and the industry associated with it\" + \\\n",
    "    \"and double check that a majority of the industries aren't the same.\"\n",
    "    \n",
    "    risk_neutral_prompt = \"Gather the financial securities that are most mentioned across the articles in a positive sentiment.\" + \\\n",
    "    f\"The securities gathered can be stocks or ETFs. Return a list of {user_prefs['num_stocks']} securities in which no more than half of the \" + \\\n",
    "    \"securities are from the same industry. \"\n",
    "    if user_prefs['industries']:\n",
    "        risk_averse_prompt += f\"Include multiple stocks with a strong focus on the following industry or industries: {user_prefs['industries']}. \"\n",
    "    risk_averse_prompt += \"Create this list so that they can be put together to make a diversified portfolio. \" + \\\n",
    "    \"List the stock name, stock ticker in parentheses, and the industry associated with it\" + \\\n",
    "    \"and double check that a majority of the industries aren't the same.\"\n",
    "    \n",
    "    risk_tolerant_prompt = \"Gather the financial securities that are most mentioned across the articles in a positive sentiment.\" + \\\n",
    "    f\"The securities gathered can be stocks or ETFs. Return a list of {user_prefs['num_stocks']} securities in which no more than half of the \" + \\\n",
    "    \"securities are from the same industry. This list of securities should also be tailored to a very risk tolerant investor who \" + \\\n",
    "    \"is more focused on rapid growth instead of stability. This list should include growth stocks with high expected returns \" + \\\n",
    "    \"with the potential for greater risk. Create this list so that they can be put together to make a diversified portfolio. \"\n",
    "    if user_prefs['industries']:\n",
    "        risk_tolerant_prompt += f\"Include multiple stocks with a strong focus on the following industry or industries: {industries}. \" \n",
    "    risk_tolerant_prompt += \"List the stock name, stock ticker in parentheses, and the industry associated with it\" + \\\n",
    "    \"and double check that a majority of the industries aren't the same.\"\n",
    "    \n",
    "    prompt_dict = {\n",
    "        \"risk_averse\": risk_averse_prompt, \n",
    "        \"risk_neutral\": risk_neutral_prompt,\n",
    "        \"risk_tolerant\": risk_tolerant_prompt\n",
    "    }\n",
    "    prompt = None\n",
    "    \n",
    "    if user_prefs[\"risk\"] == \"conservative\":\n",
    "        prompt = prompt_dict[\"risk_averse\"]\n",
    "    elif user_prefs[\"risk\"] == \"aggressive\":\n",
    "        prompt = prompt_dict[\"risk_tolerant\"]\n",
    "    else:\n",
    "        prompt = prompt_dict[\"risk_neutral\"]\n",
    "    \n",
    "    response = query_engine.query(prompt)\n",
    "    \n",
    "    pattern = r'\\(([A-Za-z]+)\\)'\n",
    "    stocks = re.findall(pattern, response.response)\n",
    "    \n",
    "    return stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a348efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_options = [\"conservative\", \"moderate\", \"aggressive\"]\n",
    "industry_options = [\"Energy\", \"Materials\", \"Industrials\", \"Utilities\", \"Healthcare\", \"Financials\", \"Consumer Discretionary\",\n",
    "                    \"Consumer Staples\", \"Technology\", \"Communication Services\", \"Real Estate\"]\n",
    "return_goals = []\n",
    "user_prefs = {\n",
    "    \"num_stocks\": None, \n",
    "    \"risk\": None, \n",
    "    \"industries\": None, \n",
    "    \"return_goals\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "643d78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA2_7B_CHAT = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "selected_model = LLAMA2_7B_CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a38a9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example user preferences\n",
    "user_prefs = {\"num_stocks\": 10, \"risk\": \"conservative\", \"industries\": None, \"return_goals\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab81ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create_documents(\"2024-05-20\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "775a0e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VOO', 'SPY', 'ACWI', 'EEM', 'VTI', 'IWM', 'DIA', 'REIT', 'VNQ', 'ACWX']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm = get_llm(selected_model)\n",
    "# get_stocks(llm, user_prefs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
